#!/usr/bin/env python3

import argparse
from uuid import uuid4
import json

import pandas as pd
import BOGP

from AmiSimTools.DataTriage import DataTriageCSV
from AmiSimTools.SimScreen import SimulatedScreenerParallel


def save_data(df, meta):
    """
    Want to save the output dataframe and the massociated meta data of the experiment to an output file.
    Can't do this as one file in pandas and hdf5 / .mat get really weird so will just use different files.
    file_id is generated by uuid4() meaning we won't need to worry about duplicate names till heat death of universe.

    :param df: DataFrame, history of the simulation we can be converted to and stored with pandas
    :param meta: dict, all the command line arguments used to set up the simulation

    """
    file_id = str(uuid4())
    meta['file_id'] = file_id

    df.to_csv(F'{file_id}.csv', index=False)
    with open(F'{file_id}.json', 'w') as f:
        f.write(json.dumps(meta, indent=4))


if __name__ == '__main__':

    data_location = r'C:\Users\crh53\OneDrive\Desktop\PHD_Experiments\E2_AMI_James\Data\Scaled_HMOF_Data.csv'
    # data_location = r'../Scaled_HCOF_F2.csv'

    parser = argparse.ArgumentParser()
    parser.add_argument('-d', '--data_file', action='store', default=data_location, help='path to data file')
    parser.add_argument('-c', '--cost', action='store', type=float, default=1.0, help='cost of experiment')
    parser.add_argument('-b', '--budget', action='store', type=float, default=1000.0, help='simulation budget')
    parser.add_argument('-n', '--nthreads', action='store', type=int, default=10, help='# of parallel threads to run')
    parser.add_argument('-i', '--initial_samples', action='store', type=int, default=20, help='# of init rand samples')
    parser.add_argument('-m', '--min_samples', action='store', type=int, default=15, help='# of exp before fit')
    parser.add_argument('-a', '--acquisition', action='store', type=str, default='Thompson', help='Acquisition func')
    args = parser.parse_args()

    sim_data = DataTriageCSV.load_from_path(args.data_file)

    sim_screen = SimulatedScreenerParallel(data_params=sim_data,
                                           test_cost=args.cost,
                                           sim_budget=args.budget,
                                           nthreads=args.nthreads,
                                           num_init=args.initial_samples,
                                           min_samples=args.min_samples)

    ami = BOGP.prospector(X=sim_data.X, acquisition_function=args.acquisition)

    sim_history = sim_screen.perform_screening(model=ami)

    df_sim = pd.DataFrame(sim_history)
    sim_meta = vars(args)
    save_data(df_sim, sim_meta)




